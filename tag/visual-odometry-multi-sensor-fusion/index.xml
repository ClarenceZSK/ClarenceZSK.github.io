<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Visual odometry, Multi-sensor fusion | Shengkai</title>
    <link>http://www.sheng-kai.top/tag/visual-odometry-multi-sensor-fusion/</link>
      <atom:link href="http://www.sheng-kai.top/tag/visual-odometry-multi-sensor-fusion/index.xml" rel="self" type="application/rss+xml" />
    <description>Visual odometry, Multi-sensor fusion</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 05 Jun 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://www.sheng-kai.top/images/icon_hu4578e1fc9e028351bfb752007350c908_42291_512x512_fill_lanczos_center_2.png</url>
      <title>Visual odometry, Multi-sensor fusion</title>
      <link>http://www.sheng-kai.top/tag/visual-odometry-multi-sensor-fusion/</link>
    </image>
    
    <item>
      <title>Conquering Textureless with RF-referenced Monocular Vision for MAV State Estimation</title>
      <link>http://www.sheng-kai.top/project/rf-assisted-monocular-visual-state-estimation-in-textureless-environments/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      <guid>http://www.sheng-kai.top/project/rf-assisted-monocular-visual-state-estimation-in-textureless-environments/</guid>
      <description>&lt;p&gt;Monocular visual based state estimators fail to work in textureless venues due to the lack of visual features or erroneous feature matching. Recently, RF sensing has been proved to be an effective sensing modality that complements the visual sensing. However, its accuracy is limited due to the large wavelength and environmental interference of RF signals. We are currently working on an exciting project that combines RF and visual sensing to fill the gap of accurate state estimation in textureless regions.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
