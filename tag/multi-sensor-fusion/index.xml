<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Multi-sensor Fusion | 张胜凯</title>
    <link>/tag/multi-sensor-fusion/</link>
      <atom:link href="/tag/multi-sensor-fusion/index.xml" rel="self" type="application/rss+xml" />
    <description>Multi-sensor Fusion</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 05 Jun 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu4578e1fc9e028351bfb752007350c908_42291_512x512_fill_lanczos_center_2.png</url>
      <title>Multi-sensor Fusion</title>
      <link>/tag/multi-sensor-fusion/</link>
    </image>
    
    <item>
      <title>RF-Visual SLAM in Textureless Venues</title>
      <link>/project/rf-assisted-monocular-visual-state-estimation-in-textureless-environments/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      <guid>/project/rf-assisted-monocular-visual-state-estimation-in-textureless-environments/</guid>
      <description>&lt;p&gt;Monocular visual based state estimators fail to work in textureless venues due to the lack of visual features or reliable feature matching. Recently, RF sensing has been proved to be an effective sensing modality that complements the visual sensing and enables estimate MAV states in textureless venues. However, its accuracy is limited due to the large wavelength of RF signals. We are currently working on an exciting project that combines RF and visual sensing and take the best of both worlds.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
